# -*- coding: utf-8 -*-
"""utils.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NRiA7cd6RZmQ6WveVbyJWPYHkRU2-aKy
"""



import torch
import torch.nn.functional as F
from torch.utils.data.dataset import Dataset
from torchvision.transforms import ToTensor
from einops import rearrange
import os
import random
import numpy as np
import imageio
import imgaug.augmenters as iaa
from func_pfm import read_pfm


class TrainSetLoader(Dataset):
    def __init__(self, config):
        super(TrainSetLoader, self).__init__()
        self.trainset_dir = config.trainset_dir
        self.source_files = sorted(os.listdir(self.trainset_dir))
        self.angRes = config.angRes
        self.patch_size = config.patch_size
        self.scene_idx = []

        scenes = [i for i in range(13)]
        for i in range(30):
            self.scene_idx += scenes

        self.length = len(self.scene_idx)

    def __getitem__(self, idx):
        scene_id = self.scene_idx[idx]
        scene_name = self.source_files[scene_id]

        lf = np.zeros((9, 9, 512, 512, 3), dtype = "uint8")
        dispGT = np.zeros((512, 512), dtype = float)
        mask = np.zeros((512, 512), dtype = float)

        for i in range(9 * 9):
            SAI_path = self.trainset_dir + scene_name + '/input_Cam0{:0>2}.png'.format(i)
            SAI = imageio.imread(SAI_path)
            lf[i // 9, i % 9, :, :, :] = SAI
        disp_path = self.trainset_dir + scene_name + '/gt_disp_lowres.pfm'
        mask_path = self.trainset_dir + scene_name + '/valid_mask.png'
        dispGT[:, :] = np.float32(read_pfm(disp_path))
        dispGT = dispGT.astype('float32')
        mask_rgb = imageio.imread(mask_path)
        mask = np.float32(mask_rgb[:, :, 1] > 0)
        
        lf, dispGT = DataAugmentation(lf, dispGT, self.patch_size)
        # lf.shape = (u v h w)
        # disp.shape = (h w)
        lf_temp = rearrange(lf, 'u v h w -> (u h) (v w)', u = self.angRes, v = self.angRes)
        # ToTensor() only supports 2-or-3-dims images
        
        data = lf_temp.astype('float32')
        label = dispGT.astype('float32')
        data = data / 255
        data = ToTensor()(data.copy())
        label = ToTensor()(label.copy())
        
        data = rearrange(data, 'c (u h) (v w) -> c u v h w', u = self.angRes, v = self.angRes)
        # data.shape = (c u v h w), c = 1
        # label.shape = (c h w), c = 1
        # /////////////////////////////////////////////////////////////
        # 获取最大值和最小值
        # max_value1 = torch.max(data[~torch.isinf(data) & ~torch.isnan(data)])  # 忽略inf和NaN
        # min_value1 = torch.min(data[~torch.isinf(data) & ~torch.isnan(data)])  # 忽略inf和NaN
        # max_value2 = torch.max(label[~torch.isinf(label) & ~torch.isnan(label)])  # 忽略inf和NaN
        # min_value2 = torch.min(label[~torch.isinf(label) & ~torch.isnan(label)])  # 忽略inf和NaN
        # 检查inf和NaN
        # has_inf = torch.any(torch.isinf(data))
        # has_nan = torch.any(torch.isnan(data))

        # print("最大值:", max_value1.item())
        # print("最小值:", min_value1.item())
        # print("最大值:", max_value2.item())
        # print("最小值:", min_value2.item())
        # print("包含inf:", has_inf.item())
        # print("包含NaN:", has_nan.item())
        # /////////////////////////////////////////////////////////////
        return data, label

    def __len__(self):
        return self.length


class AllSetLoader(Dataset):
    def __init__(self, config, kind):
        super(AllSetLoader, self).__init__()
        self.dataset_dir = None
        if kind == "valid":
            self.dataset_dir = config.validset_dir
        elif kind == "test":
            self.dataset_dir = config.testset_dir
        self.source_files = sorted(os.listdir(self.dataset_dir))
        self.angRes = config.angRes
        self.length = len(self.source_files)
        
    def __getitem__(self, idx):
        scene_name = self.source_files[idx]
        
        lf = np.zeros((9, 9, 512, 512, 3), dtype = "uint8")
        dispGT = np.zeros((512, 512), dtype = float)

        for i in range(9 * 9):
            SAI_path = self.dataset_dir + scene_name + '/input_Cam0{:0>2}.png'.format(i)
            SAI = imageio.imread(SAI_path)
            lf[i // 9, i % 9, :, :, :] = SAI
        disp_path = self.dataset_dir + scene_name + '/gt_disp_lowres.pfm'
        dispGT[:, :] = np.float32(read_pfm(disp_path))
        
        lf = np.mean(lf, axis = -1, keepdims = False) / 255
        lf = rearrange(lf, 'u v h w -> (u h) (v w)', u = self.angRes, v = self.angRes)
        lf = lf.astype('float32')
        dispGT = dispGT.astype('float32')
        lf = ToTensor()(lf.copy())
        dispGT = ToTensor()(dispGT.copy())
        lf = rearrange(lf, 'c (u h) (v w) -> c u v h w', u = self.angRes, v = self.angRes)
        # lf.shape = (c u v h w), c = 1
        # dispGT.shape = (c h w), c = 1
        
        return lf, dispGT

    def __len__(self):
        return self.length
        

def DataAugmentation(lf, disp, patch_size):
    # lf.shape = (u v h w c), c = RGB
    # disp.shape = (h w)
    lf = np.reshape(lf, (81, 512, 512, 3))

    lf_Aug1 = IlluminanceAugmentation(lf)
    # lf_Aug1.shape = ((u v) h w)
    lf_Aug2, disp_Aug1 = ScaleAugmentation(lf_Aug1, disp)
    lf_Aug3, disp_Aug2 = OrientationAugmentation(lf_Aug2, disp_Aug1)
    lf_Aug4, disp_Aug3 = RandomCrop(lf_Aug3, disp_Aug2, patch_size)

    lf_Aug4 = rearrange(lf_Aug4, '(u v) h w -> u v h w', u=9, v=9)
    return lf_Aug4, disp_Aug3


def IlluminanceAugmentation(lf):
    # lf.shape = ((u v) h w c), c = RGB
    rand_params = [np.random.randint(-100, 100), 
                   np.random.randint(-50, 50), 
                   np.random.uniform(0.0, 1.0), 
                   np.random.uniform(0.0, 0.05 * 255)]

    seq = iaa.Sequential([
        iaa.AddToBrightness(rand_params[0]),
        iaa.AddToHue(rand_params[1]),
        iaa.Grayscale(alpha = rand_params[2]),
        iaa.AdditiveGaussianNoise(loc = 0, scale = rand_params[3], per_channel = False),
    ])

    lf_Aug = seq(images = lf)

    randRGB = 0.05 + np.random.rand(3)
    randRGB /= np.sum(randRGB)  # Normalize
    lf_Gray = np.dot(lf_Aug, randRGB)

    lf_Gray = np.clip(lf_Gray, 0, 255).astype(np.uint8)

    return lf_Gray
def IlluminanceAugmentation1(data):
    data = np.reshape(data, (9, 9, 512, 512, 3))
    # 照明增强处理：包括色彩变换、亮度调整、加入随机噪声
    # 用于提高数据多样性与模型鲁棒性
    rand_3color = 0.05 + np.random.rand(3)
    # 随机生成三元组，值域[0.05, 1.05)
    # 代表RGB三色的混合权重，用于根据彩图生成灰度图
    rand_3color = rand_3color / np.sum(rand_3color)
    # 归一化
    R = rand_3color[0]
    G = rand_3color[1]
    B = rand_3color[2]
    data_gray = np.squeeze(R * data[:, :, :, :, 0] + G * data[:, :, :, :, 1] + B * data[:, :, :, :, 2])
    # 将RGB三色按随机权重加和，得到灰度图
    gray_rand = 0.4 * np.random.rand() + 0.8
    # 随机生成亮度，值域[0.8, 1.2)
    data_gray = pow(data_gray, gray_rand)
    # 通过幂运算随机调整亮度
    noise_rand = np.random.randint(0, 10)
    if noise_rand == 0:
        # 随机生成0到9的一个整数
        # 若为0（10%概率），则添加随机噪声
        gauss = np.random.normal(0.0, np.random.uniform() * np.sqrt(0.2), data_gray.shape)
        # 生成平均数为0，标准差随机，与灰度图shape相同的，符合正态分布的随机噪声
        data_gray = np.clip(data_gray + gauss, 0.0, 1.0)
        # 将灰度图的各像素值限制在0到1之间（超出边界的，直接用边界值替换）
    return data_gray


def ScaleAugmentation(lf, disp):
    # lf.shape = ((u v) h w), disp.shape = (h w)
    
    rand_scale = np.random.uniform(0.0, 3.0)
    if rand_scale < 1.5:
        scale = 1
    elif rand_scale < 2.5:
        scale = 2
    else:
        scale = 3
    percent = (scale - 1) / (2 * scale)

    seq = iaa.Sequential([iaa.Crop(percent = percent)])

    lf_Aug = seq(images = lf)
    disp_Aug = seq(images = disp)

    disp_Aug /= scale

    return lf_Aug, disp_Aug
def ScaleAugmentation1(lf, dispGT):
    kk = np.random.randint(17)
    if (kk < 8):
        scale = 1
    elif (kk < 14):
        scale = 2 
        # 分辨率缩放至原来的1/2
    elif (kk < 17):
        scale = 3
        # 分辨率缩放至原来的1/3
    out_lf = lf[:, :, 0::scale, 0::scale]
    out_disp = dispGT[0::scale, 0::scale]
    # 每scale个像素采样一次
    # 下采样，会导致图像分辨率（尺寸）降低
    out_disp[:, :] = out_disp[:, :] / scale
    # 图像缩放后，各像素的原始视差值也要按相同比例缩放

    return out_lf, out_disp


def OrientationAugmentation(lf, disp):
    # lf.shape = ((u v) h w), disp.shape = (h w)

    rand1, rand2, rand3 = np.random.rand(3)

    aug_list = []
    if rand1 > 0.5:
        aug_list.append(iaa.Fliplr(p = 1))
    if rand2 > 0.5:
        aug_list.append(iaa.Flipud(p = 1))
    if rand3 > 0.75:
        aug_list.append(iaa.Rotate(rotate = 90))
    elif rand3 > 0.5:
        aug_list.append(iaa.Rotate(rotate = -90))

    if aug_list:
        seq = iaa.Sequential(aug_list)
        lf = seq(images = lf)
        disp = seq(images = disp)

    return lf, disp
def OrientationAugmentation1(data, dispGT):
    data = rearrange(data, 'u v h w -> (u h) (v w)', u=9, v=9)
    if random.random() < 0.5:  # flip along W-V direction
        # 水平翻转
        data = data[:, ::-1]
        dispGT = dispGT[:, ::-1]
    if random.random() < 0.5:  # flip along H-U direction
        # 垂直翻转
        data = data[::-1, :]
        dispGT = dispGT[::-1, :]
    if random.random() < 0.5: # transpose between U-V and H-W
        # 旋转90度
        data = data.transpose(1, 0)
        dispGT = dispGT.transpose(1, 0)
    data = rearrange(data, '(u h) (v w) -> u v h w', u=9, v=9)
    return data, dispGT

def RandomCrop(lf, disp, patch_size):
    # lf.shape = ((u v) h w), disp.shape = (h w)
    _, h, w = lf.shape

    h_crop = np.random.randint(0, h - patch_size)
    w_crop = np.random.randint(0, w - patch_size)
    lf_crop = lf[:, h_crop : h_crop + patch_size, w_crop : w_crop + patch_size]
    disp_crop = disp[h_crop : h_crop + patch_size, w_crop : w_crop + patch_size]
    
    # lf.shape = ((u v) h w), disp.shape = (h w), h = w = patch_size
    return lf_crop, disp_crop