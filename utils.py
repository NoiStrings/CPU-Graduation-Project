# -*- coding: utf-8 -*-
"""utils.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NRiA7cd6RZmQ6WveVbyJWPYHkRU2-aKy
"""



import torch
import torch.nn.functional as F
from torch.utils.data.dataset import Dataset
from torchvision.transforms import ToTensor
from einops import rearrange
import os
import numpy as np
import imageio
import imgaug.augmenters as iaa
from func_pfm import read_pfm


class TrainSetLoader(Dataset):
    def __init__(self, config):
        super(TrainSetLoader, self).__init__()
        self.trainset_dir = config.trainset_dir
        self.source_files = sorted(os.listdir(self.trainset_dir))
        self.angRes = config.angRes
        self.patch_size = config.patch_size
        self.scene_idx = []

        no_reflection_idx = [0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 12, 13, 14]
        with_reflection_idx = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
        for i in range(40):
            self.scene_idx += no_reflection_idx
        '''for i in range(20):
            self.scene_idx += with_reflection_idx'''

        self.length = len(self.scene_idx)

    def __getitem__(self, idx):
        scene_id = self.scene_idx[idx]
        scene_name = self.source_files[scene_id]

        lf = np.zeros((9, 9, 512, 512, 3), dtype = "uint8")
        dispGT = np.zeros((512, 512), dtype = "float32")
        mask = np.zeros((512, 512), dtype = "float32")

        for i in range(9 * 9):
            SAI_path = self.trainset_dir + scene_name + '/input_Cam0{:0>2}.png'.format(i)
            SAI = imageio.imread(SAI_path)
            lf[i // 9, i % 9, :, :, :] = SAI
        disp_path = self.trainset_dir + scene_name + '/gt_disp_lowres.pfm'
        mask_path = self.trainset_dir + scene_name + '/valid_mask.png'
        dispGT[:, :] = np.float32(read_pfm(disp_path))
        mask_rgb = imageio.imread(mask_path)
        mask = np.float32(mask_rgb[:, :, 1] > 0)

        lf, dispGT = DataAugmentation(lf, dispGT, self.patch_size)
        # lf.shape = (u v h w)
        # disp.shape = (h w)
        lf_temp = rearrange(lf, 'u v h w -> (u h) (v w)', u = self.angRes, v = self.angRes)
        # ToTensor() only supports 2-or-3-dims images
        
        data = lf_temp.astype('float32')
        label = dispGT.astype('float32')
        data = ToTensor()(data.copy())
        label = ToTensor()(label.copy())
        
        data = rearrange(data, 'c (u h) (v w) -> c u v h w', u = self.angRes, v = self.angRes)
        # data.shape = (c u v h w), c = 1
        # label.shape = (c h w), c = 1

        return data, label

    def __len__(self):
        return self.length


class AllSetLoader(Dataset):
    def __init__(self, config, kind):
        super(AllSetLoader, self).__init__()
        self.dataset_dir = None
        if kind == "valid":
            self.dataset_dir = config.validset_dir
        elif kind == "test":
            self.dataset_dir = config.testset_dir
        self.source_files = sorted(os.listdir(self.dataset_dir))
        self.angRes = config.angRes
        self.length = len(self.source_files)
        
    def __getitem__(self, idx):
        scene_name = self.source_files[idx]
        
        lf = np.zeros((9, 9, 512, 512, 3), dtype = "uint8")
        dispGT = np.zeros((512, 512), dtype = "float32")

        for i in range(9 * 9):
            SAI_path = self.validset_dir + scene_name + '/input_Cam0{:0>2}.png'.format(i)
            SAI = imageio.imread(SAI_path)
            lf[i // 9, i % 9, :, :, :] = SAI
        disp_path = self.validset_dir + scene_name + '/gt_disp_lowres.pfm'
        dispGT[:, :] = np.float32(read_pfm(disp_path))
        
        lf = np.mean(lf, axis = -1, keepdim = False) / 255
        # lf.shape = (u v h w)
        # dispGT.shape = (h w)
        
        return lf, dispGT

    def __len__(self):
        return self.length
        

def DataAugmentation(lf, disp, patch_size):
    # lf.shape = (u v h w c), c = RGB
    # disp.shape = (h w)
    lf = np.reshape(lf, (81, 512, 512, 3))

    lf_Aug1 = IlluminanceAugmentation(lf)
    # lf_Aug1.shape = ((u v) h w)
    lf_Aug2, disp_Aug1 = ScaleAugmentation(lf_Aug1, disp)
    lf_Aug3, disp_Aug2 = OrientationAugmentation(lf_Aug2, disp_Aug1)
    lf_Aug4, disp_Aug3 = RandomCrop(lf_Aug3, disp_Aug2, patch_size)

    lf_Aug4 = np.reshape(lf_Aug4, (9, 9, patch_size, patch_size))
    return lf_Aug4, disp_Aug3


def IlluminanceAugmentation(lf):
    # lf.shape = ((u v) h w c), c = RGB
    rand_params = [np.random.randint(-100, 100), 
                   np.random.randint(-50, 50), 
                   np.random.uniform(0.0, 1.0), 
                   np.random.uniform(0.0, 0.05 * 255)]

    seq = iaa.Sequential([
        iaa.AddToBrightness(rand_params[0]),
        iaa.AddToHue(rand_params[1]),
        iaa.Grayscale(alpha = rand_params[2]),
        iaa.AdditiveGaussianNoise(loc = 0, scale = rand_params[3], per_channel = False),
    ])

    lf_Aug = seq(images = lf)

    randRGB = 0.05 + np.random.rand(3)
    randRGB /= np.sum(randRGB)  # Normalize
    lf_Gray = np.dot(lf_Aug, randRGB)

    lf_Gray = np.clip(lf_Gray, 0, 255).astype(np.uint8)

    return lf_Gray


def ScaleAugmentation(lf, disp):
    # lf.shape = ((u v) h w), disp.shape = (h w)
    
    rand_scale = np.random.uniform(0.0, 3.0)
    if rand_scale < 1.5:
        scale = 1
    elif rand_scale < 2.5:
        scale = 2
    else:
        scale = 3
    percent = (scale - 1) / (2 * scale)

    seq = iaa.Sequential([iaa.Crop(percent = percent)])

    lf_Aug = seq(images = lf)
    disp_Aug = seq(images = disp)

    disp_Aug /= scale

    return lf_Aug, disp_Aug


def OrientationAugmentation(lf, disp):
    # lf.shape = ((u v) h w), disp.shape = (h w)

    rand1, rand2, rand3 = np.random.rand(3)

    aug_list = []
    if rand1 > 0.5:
        aug_list.append(iaa.Fliplr(p = 1))
    if rand2 > 0.5:
        aug_list.append(iaa.Flipud(p = 1))
    if rand3 > 0.75:
        aug_list.append(iaa.Rotate(rotate = 90))
    elif rand3 > 0.5:
        aug_list.append(iaa.Rotate(rotate = -90))

    if aug_list:
        seq = iaa.Sequential(aug_list)
        lf = seq(images = lf)
        disp = seq(images = disp)

    return lf, disp


def RandomCrop(lf, disp, patch_size):
    # lf.shape = ((u v) h w), disp.shape = (h w)
    _, h, w = lf.shape

    h_crop = np.random.randint(0, h - patch_size)
    w_crop = np.random.randint(0, w - patch_size)
    lf_crop = lf[:, h_crop : h_crop + patch_size, w_crop : w_crop + patch_size]
    disp_crop = disp[h_crop : h_crop + patch_size, w_crop : w_crop + patch_size]
    
    # lf.shape = ((u v) h w), disp.shape = (h w), h = w = patch_size
    return lf_crop, disp_crop